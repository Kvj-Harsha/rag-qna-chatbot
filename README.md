

# ğŸ’¬ RAG-QnA Chatbot

A **Retrieval-Augmented Generation (RAG)** based chatbot built using **Streamlit**, **ChromaDB**, and **OpenAI API**, designed to ingest documents and answer user queries contextually.

---

![diagram (6)](https://github.com/user-attachments/assets/52257720-ffd0-47b0-ab9a-11d1f1623b05)

---

## ğŸ“ Project Structure

```bash
â”œâ”€â”€ main.py                          # Streamlit app entry point
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ ingest_page.py              # Handles document upload and ingestion
â”‚   â””â”€â”€ chatbot_page.py             # Handles QnA interface
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ chroma_services.py         # Vector DB operations using Chroma
â”‚   â””â”€â”€ genai_services.py          # OpenAI API interaction
â”œâ”€â”€ data/
â”‚   â””â”€â”€ data.txt                    # Sample source document
â”œâ”€â”€ .env                            # Environment variables (template)
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # Project overview
```

---

## ğŸš€ Getting Started

### 1. Clone the Repo

```bash
git clone https://github.com/your-username/rag-qna-chatbot.git
cd rag-qna-chatbot
```

### 2. Set Up Environment

Create a `.env` file based on the `template.env` and add your API keys and config:

```env
OPENAI_API_KEY=your_openai_key
CHROMA_DB_PATH=./data
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Run the App

```bash
streamlit run main.py
```

---

## ğŸ” Features

- ğŸ“„ **Document Ingestion**: Upload documents via the **Ingest Page** (`pages/ingest_page.py`)
- ğŸ’¡ **Semantic Search**: Retrieves context from documents using **ChromaDB**
- ğŸ§  **Answer Generation**: Uses **OpenAI API** to answer questions with contextual awareness
- ğŸ“Š **Modular Layers**:
  - Presentation Layer: Streamlit UI
  - Service Layer: Vector DB + GenAI handling
  - Data Layer: Source documents and embeddings

---

## ğŸ› ï¸ Internals

### Streamlit Entry (`main.py`)
- Registers both `Ingest` and `Chatbot` pages.
- Entry point of the app.

### Ingest Page
- Lets user upload `.txt` files.
- Extracts embeddings and stores in **ChromaDB** using `chroma_services.py`.

### Chatbot Page
- Allows users to ask questions.
- Retrieves relevant context via `chroma_services.py`.
- Sends context + question to OpenAI using `genai_services.py`.

### Service Layer
- `chroma_services.py`: Stores, queries, and retrieves embeddings.
- `genai_services.py`: Calls OpenAI's completion endpoint.

---

## ğŸ§ª Sample Data

A sample document is included at `data/data.txt` for quick testing.

---

## ğŸ“„ Dependencies

Make sure these are included in your `requirements.txt`:

```txt
streamlit
chromadb
openai
python-dotenv
```

---

## ğŸ“˜ Documentation

- Project Overview: [`README.md`](README.md)
- Setup Guide: [`requirements.txt`](requirements.txt)
- Environment Configs: [`template.env`](template.env)

---

## ğŸ“¬ Contact

For questions, issues, or contributions, please raise an issue or PR on GitHub.
